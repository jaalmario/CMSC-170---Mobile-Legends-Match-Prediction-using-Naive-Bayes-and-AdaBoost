{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import seaborn as sns\n",
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Game</th>\n",
       "      <th>Team</th>\n",
       "      <th>Hero</th>\n",
       "      <th>Stat</th>\n",
       "      <th>Role</th>\n",
       "      <th>Best Attribute</th>\n",
       "      <th>Actual Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player  Game  Team  Hero  Stat  Role  Best Attribute  Actual Result\n",
       "0       1   1.0     1    95   1.0     0             0.0              1\n",
       "1       2   1.0     1    28   1.0     1             1.0              1\n",
       "2       3   1.0     1    26   0.0     2             0.0              1\n",
       "3       4   1.0     1    30   0.0     3             2.0              1\n",
       "4       5   1.0     2    95   1.0     0             0.0              0\n",
       "5       6   1.0     2    47   0.0     3             1.0              0\n",
       "6       7   1.0     2    20   1.0     5             0.0              0\n",
       "7       8   1.0     2     9   0.0     1             1.0              0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockData = pd.read_csv(\"ML_Data2.csv\")\n",
    "stockData.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA\n",
    "\n",
    "before we can proceed to our Naive Bayes, we must confirm that the features we have are independent and are not correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = stockData.iloc[:,4:-1].corr(method=\"pearson\")\n",
    "cmap = sns.diverging_palette(250,354,80,60,center='dark',as_cmap=True)\n",
    "sns.heatmap(corr, vmax=1, vmin=-.5, cmap=cmap, square=True, linewidths=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Prior P(Y)\n",
    "Logic for this would be P(Y) = totalY/totalN; Y = Win | Lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior(training_d,Y):\n",
    "    classes = sorted(list(training_d[Y].unique()))\n",
    "    prior = []\n",
    "    for i in classes:\n",
    "        prior.append(len(training_d[training_d[Y]==i])/len(training_d))\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate P(X|Y) \n",
    "logic here is P(X|Y) = totalX/totalN; X = x0 | x1 | x2 (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(training_d, feat_name, feat_val, Y, label):\n",
    "    training_d = training_d[training_d[Y]==label]\n",
    "    p_x_given_y = len(training_d[training_d[feat_name]==feat_val]) / len(training_d)\n",
    "    return p_x_given_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Probability P(X1|Y)P(X2|Y)P(X3|Y)...P(Xn|Y) * P(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_categorical(training_data, X, Y):\n",
    "    #getting the feature names\n",
    "    features = list(training_data.columns)[4:-1]\n",
    "    \n",
    "    prior = calculate_prior(training_data, Y)\n",
    "    \n",
    "    probW = []\n",
    "    probL = []\n",
    "    Ypred = []\n",
    "    data = [[],[],[]]\n",
    "    accumulatedP = [],[]\n",
    "    for x in X:\n",
    "        \n",
    "        labels = sorted(list(training_data[Y].unique()))\n",
    "        likelihood = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            #calculate P(X1|Y)P(X2|Y)P(X3|Y)...P(Xn|Y)\n",
    "            for i in range(len(features)):\n",
    "                likelihood[j] *= calculate_likelihood(training_data, features[i], x[i], Y, labels[j])\n",
    "        post_prob = [1]*len(labels)\n",
    "        \n",
    "        for j in range(len(labels)):\n",
    "            post_prob[j] = likelihood[j] * prior[j]\n",
    "               \n",
    "    \n",
    "        Ypred.append(np.argmax(post_prob))\n",
    "        probW.append(post_prob[1])\n",
    "        probL.append(post_prob[0])\n",
    "    \n",
    "    #Since there are 4 heroes per team, their probability are all multiplied\n",
    "    for i in range(floor(len(X)/4)):\n",
    "           accumulatedP[1].append(probW[i*4]*probW[(i*4)+1]*probW[(i*4)+2]*probW[(i*4)+3]) \n",
    "           accumulatedP[0].append(probL[i*4]*probL[(i*4)+1]*probL[(i*4)+2]*probL[(i*4)+3])\n",
    "           # We predict win if their win prob is greater than their lose prob.\n",
    "           if(accumulatedP[1][i] >= accumulatedP[0][i]):\n",
    "               data[2].append(1)\n",
    "           else:\n",
    "               data[2].append(0)\n",
    "\n",
    "    data[0] = accumulatedP[0]\n",
    "    data[1] = accumulatedP[1]\n",
    "    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing For NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [0. 4. 1.]\n",
      " [1. 5. 2.]\n",
      " ...\n",
      " [0. 4. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 5. 2.]]\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1\n",
      " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0]\n",
      "     Prediction  Win Probability  Lose Probability  Actual Result\n",
      "0             1     4.665970e-09      4.219304e-09              1\n",
      "1             0     7.017289e-08      1.299873e-07              0\n",
      "2             1     4.777239e-07      3.740949e-07              0\n",
      "3             1     8.225098e-08      7.736492e-08              1\n",
      "4             0     6.403432e-08      7.736492e-08              0\n",
      "5             0     4.999200e-08      6.165328e-08              1\n",
      "6             0     7.120234e-08      7.792554e-08              1\n",
      "7             0     6.672108e-08      7.573045e-08              0\n",
      "8             1     2.345644e-08      1.649030e-08              1\n",
      "9             0     2.118248e-07      2.897241e-07              0\n",
      "10            1     2.345644e-08      1.649030e-08              1\n",
      "11            1     8.225098e-08      7.736492e-08              0\n",
      "12            0     2.038649e-07      2.358687e-07              0\n",
      "13            0     1.764801e-07      2.375779e-07              1\n",
      "14            1     2.345644e-08      1.649030e-08              0\n",
      "15            1     1.171480e-07      9.778398e-08              1\n",
      "16            1     1.353261e-07      9.708050e-08              0\n",
      "17            1     3.859248e-08      2.069266e-08              1\n",
      "18            0     4.999200e-08      6.165328e-08              0\n",
      "19            0     7.120234e-08      7.792554e-08              1\n",
      "20            1     2.691917e-08      2.483959e-08              1\n",
      "21            1     4.394339e-08      4.270588e-08              0\n",
      "22            1     8.225098e-08      7.736492e-08              1\n",
      "23            0     3.292539e-08      3.476749e-08              0\n",
      "24            1     2.345644e-08      1.649030e-08              0\n",
      "25            1     2.185597e-08      1.430985e-08              1\n",
      "26            1     2.345644e-08      1.649030e-08              1\n",
      "27            1     1.328402e-08      1.140374e-08              0\n",
      "28            0     1.653730e-07      2.308855e-07              0\n",
      "29            0     4.055295e-08      6.035075e-08              1\n",
      "30            1     2.691917e-08      2.483959e-08              1\n",
      "31            0     6.672108e-08      7.573045e-08              0\n",
      "32            1     1.097751e-07      9.502950e-08              1\n",
      "33            1     1.994406e-08      8.516833e-09              0\n",
      "34            0     7.397068e-08      7.680834e-08              1\n",
      "35            0     3.157142e-08      6.035075e-08              0\n",
      "36            0     4.999200e-08      6.165328e-08              0\n",
      "37            1     1.053546e-07      9.708050e-08              1\n",
      "38            1     6.349555e-08      2.596595e-08              0\n",
      "39            1     6.497372e-08      5.203515e-08              1\n",
      "40            1     1.353261e-07      9.708050e-08              1\n",
      "41            1     1.097751e-07      9.502950e-08              0\n",
      "42            0     4.999200e-08      6.165328e-08              0\n",
      "43            0     2.903597e-07      3.344782e-07              1\n",
      "44            1     3.859248e-08      2.069266e-08              1\n",
      "45            0     9.365521e-08      1.596671e-07              0\n",
      "46            1     1.353261e-07      9.708050e-08              0\n",
      "47            1     0.000000e+00      0.000000e+00              1\n",
      "48            1     1.353261e-07      9.708050e-08              1\n",
      "49            0     1.764801e-07      2.375779e-07              0\n",
      "50            1     1.353261e-07      9.708050e-08              1\n",
      "51            1     1.826139e-08      1.649030e-08              0\n",
      "52            1     8.225098e-08      7.736492e-08              1\n",
      "53            0     8.546246e-08      9.502950e-08              0\n",
      "54            1     1.353261e-07      9.708050e-08              1\n",
      "55            0     4.999200e-08      6.165328e-08              0\n",
      "56            1     2.345644e-08      1.649030e-08              0\n",
      "57            1     2.437229e-08      2.025549e-08              1\n",
      "58            0     2.038649e-07      2.358687e-07              0\n",
      "59            1     1.902760e-08      1.614191e-08              1\n",
      "60            1     8.225098e-08      7.736492e-08              0\n",
      "61            0     4.999200e-08      6.165328e-08              1\n",
      "62            0     4.999200e-08      6.165328e-08              0\n",
      "63            1     2.583517e-08      2.537569e-08              1\n",
      "64            1     1.353261e-07      9.708050e-08              1\n",
      "65            0     7.120234e-08      7.792554e-08              0\n",
      "66            0     1.239087e-07      1.879673e-07              0\n",
      "67            1     4.250617e-08      3.184240e-08              1\n",
      "68            1     1.184618e-08      3.799896e-09              1\n",
      "69            1     4.943278e-08      2.596595e-08              0\n",
      "70            0     4.327665e-08      6.210004e-08              0\n",
      "71            0     2.720853e-07      2.897241e-07              1\n",
      "72            1     1.353261e-07      9.708050e-08              1\n",
      "73            1     6.349555e-08      2.596595e-08              0\n",
      "74            0     1.239087e-07      1.879673e-07              0\n",
      "75            1     4.250617e-08      3.184240e-08              1\n",
      "76            1     8.225098e-08      7.736492e-08              1\n",
      "77            0     1.899549e-07      2.046807e-07              0\n",
      "78            1     3.859248e-08      2.069266e-08              1\n",
      "79            1     5.417159e-08      4.362759e-08              0\n",
      "80            0     4.999200e-08      6.165328e-08              1\n",
      "81            0     7.120234e-08      7.792554e-08              0\n",
      "82            1     5.518535e-07      3.714036e-07              1\n",
      "83            1     3.859248e-08      2.069266e-08              0\n",
      "84            0     3.038504e-08      4.913243e-08              0\n",
      "85            1     1.328402e-08      1.140374e-08              1\n",
      "86            1     6.349555e-08      2.596595e-08              0\n",
      "87            1     1.790691e-07      1.597933e-07              1\n",
      "88            0     4.658097e-08      5.350111e-08              0\n",
      "89            1     1.171480e-07      9.778398e-08              1\n",
      "90            1     8.225098e-08      7.736492e-08              1\n",
      "91            0     7.017289e-08      1.299873e-07              0\n",
      "92            1     3.595926e-08      1.795655e-08              1\n",
      "93            0     7.120234e-08      7.792554e-08              0\n",
      "94            1     3.859248e-08      2.069266e-08              1\n",
      "95            0     2.355365e-07      2.918235e-07              0\n",
      "96            1     3.859248e-08      2.069266e-08              1\n",
      "97            0     4.020673e-08      8.087139e-08              0\n",
      "98            1     3.859248e-08      2.069266e-08              1\n",
      "99            1     8.912759e-08      5.474559e-08              0\n",
      "100           1     2.345644e-08      1.649030e-08              1\n",
      "101           1     1.994406e-08      8.516833e-09              0\n",
      "102           1     2.226498e-07      1.218204e-07              0\n",
      "103           1     1.212196e-08      6.787193e-09              1\n",
      "104           0     7.746271e-07      7.830526e-07              1\n",
      "105           1     1.425678e-08      1.314137e-08              0\n",
      "106           1     1.425678e-08      1.314137e-08              1\n",
      "107           1     2.185597e-08      1.430985e-08              0\n",
      "108           1     3.354155e-07      2.959771e-07              0\n",
      "109           0     1.764801e-07      2.375779e-07              1\n",
      "110           1     2.345644e-08      1.649030e-08              0\n",
      "111           1     1.097751e-07      9.502950e-08              1\n",
      "112           0     1.154543e-07      1.631132e-07              1\n",
      "113           0     4.327665e-08      6.210004e-08              0\n",
      "114           1     1.353261e-07      9.708050e-08              1\n",
      "115           1     5.417159e-08      4.362759e-08              0\n",
      "116           0     4.999200e-08      6.165328e-08              1\n",
      "117           0     1.764801e-07      2.375779e-07              0\n",
      "118           0     4.999200e-08      6.165328e-08              1\n",
      "119           1     1.902760e-08      1.614191e-08              0\n",
      "120           1     3.354155e-07      2.959771e-07              0\n",
      "121           0     6.672108e-08      7.573045e-08              1\n",
      "122           1     7.663888e-08      6.713527e-08              0\n",
      "123           1     2.583517e-08      2.537569e-08              1\n",
      "124           1     1.806110e-07      1.192467e-07              0\n",
      "125           1     1.097751e-07      9.502950e-08              1\n",
      "126           1     1.826139e-08      1.649030e-08              0\n",
      "127           1     1.097751e-07      9.502950e-08              1\n",
      "128           1     1.826139e-08      1.649030e-08              0\n",
      "129           1     1.171480e-07      9.778398e-08              1\n",
      "130           1     3.125296e-07      2.568413e-07              1\n",
      "131           1     7.663888e-08      6.713527e-08              0\n",
      "132           0     1.109924e-08      1.314137e-08              1\n",
      "133           0     1.431587e-07      2.325586e-07              0\n",
      "134           1     8.225098e-08      7.736492e-08              1\n",
      "135           0     1.764801e-07      2.375779e-07              0\n",
      "136           0     4.999200e-08      6.165328e-08              1\n",
      "137           0     1.764801e-07      2.375779e-07              0\n",
      "138           0     2.038649e-07      2.358687e-07              0\n",
      "139           1     1.927416e-07      1.227031e-07              1\n",
      "140           1     2.345644e-08      1.649030e-08              0\n",
      "141           1     4.296309e-07      3.714036e-07              1\n",
      "142           0     4.999200e-08      6.165328e-08              1\n",
      "143           1     1.902760e-08      1.614191e-08              0\n",
      "144           1     3.354155e-07      2.959771e-07              0\n",
      "145           0     6.672108e-08      7.573045e-08              1\n",
      "146           0     3.038504e-08      4.913243e-08              0\n",
      "147           0     1.720788e-08      3.397716e-08              1\n",
      "148           1     1.263058e-08      6.643802e-09              1\n",
      "149           1     1.994406e-08      8.516833e-09              0\n",
      "Accuracy:  0.6066666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(stockData, test_size=.3, shuffle=False)\n",
    "X_test = test.iloc[:,4:-1].values\n",
    "Y_test = test.iloc[:,-1].values\n",
    "\n",
    "Ypred = naive_bayes_categorical(train, X=X_test, Y=\"Actual Result\")\n",
    "\n",
    "match_y =[]\n",
    "for i in range(floor(len(X_test)/4)):\n",
    "    match_y.append(Y_test[i*4])\n",
    "\n",
    "result = pd.DataFrame({\"Prediction\":Ypred[2],\"Win Probability\": Ypred[1], \"Lose Probability\": Ypred[0],\"Actual Result\":match_y})\n",
    "\n",
    "# Calculate Accuracy by the total correct predictions divided by the total Matches\n",
    "acc = np.sum(result[\"Prediction\"] == result[\"Actual Result\"]) / len(result[\"Actual Result\"])\n",
    "print_full(result)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "405ef7d1e9e1734bac154fb68f09c8e6b1313a2ff423ae8052b2bdaf32a1ee30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
